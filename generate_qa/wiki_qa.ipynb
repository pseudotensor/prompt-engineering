{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval Augmented Generation with Anthropic + Generated Q/A"
      ],
      "metadata": {
        "id": "pWkkuulhyyx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -U typing-extensions\n",
        "!pip install anthropic\n",
        "!pip install wikipedia"
      ],
      "metadata": {
        "id": "fGumS80I_8jL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import anthropic\n",
        "import wikipedia\n",
        "\n",
        "API_KEY = \"fill me\"  # anthropic api key\n",
        "MODEL_NAME = \"claude-2.1\"\n",
        "client = anthropic.Anthropic(api_key=API_KEY)\n",
        "\n",
        "def get_completion(prompt: str, temperature=0, system=\"You are an expert information retrieval system.\"):\n",
        "    message = client.messages.create(\n",
        "        model=MODEL_NAME,\n",
        "        max_tokens=1024,\n",
        "        temperature=temperature,\n",
        "        messages=[\n",
        "          {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        system=system,\n",
        "    )\n",
        "    return message.content[0].text\n",
        "\n",
        "def get_wikipedia_search_results(query: str, n_search_results_to_use=1):\n",
        "  \"\"\"Call the wikipedia API and get back article content, title, and source.\"\"\"\n",
        "  results: list[str] = wikipedia.search(query)\n",
        "  search_results: list[dict] = []\n",
        "  for result in results:\n",
        "    if len(search_results) >= n_search_results_to_use:\n",
        "      break\n",
        "    try:\n",
        "      page = wikipedia.page(result)\n",
        "    except:\n",
        "      # The Wikipedia API is a little flaky, so we just skip over pages that fail to load\n",
        "      continue\n",
        "\n",
        "    search_result = {\n",
        "        \"content\": page.content,\n",
        "        \"title\": page.title,\n",
        "        \"source\": page.url\n",
        "    }\n",
        "\n",
        "    search_results.append(search_result)\n",
        "\n",
        "  tokenizer = anthropic.Anthropic().get_tokenizer()\n",
        "  for search_result in search_results:\n",
        "    ids = tokenizer.encode(search_result['content']).ids[:5000]\n",
        "    search_result['content'] = tokenizer.decode(ids)\n",
        "  return search_results"
      ],
      "metadata": {
        "id": "GIqhT8GXDyd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AONfP2RkK4qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1: Answer Questions with Wikipedia\n",
        "Please complete the function ask_clawd() below so that Claude can answer questions using Wikipedia data.\n",
        "\n",
        "Focus on the *quality* of your generated answers over their *latency*."
      ],
      "metadata": {
        "id": "WSXgOfHKLA0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_clawd(query: str):\n",
        "    new_query = get_completion(f\"Consider this prompt by user: {query}.  Rephrase the prompt for lookup in wikipedia, i.e. remove unnecessary words.\", temperature=0.3, system='You are a helpful assistant.')\n",
        "    print(\"%s -> %s\", (query, new_query))\n",
        "    search_results = get_wikipedia_search_results(new_query, n_search_results_to_use=20)\n",
        "\n",
        "    #print(len(search_results))\n",
        "    search_results_concat = '\\n'.join(['<title>\\n%s\\n</title>\\n<source>\\n%s</source>\\n<content>%s</content>' % (d['title'], d['source'], d['content']) for d in search_results])\n",
        "    #print(search_results_concat)\n",
        "    prompt = f\"{search_results_concat}\\nYou will follow these steps: 1) Give your thoughts inside <thinking></thinking> xml tags.\\n 2) According to the information provided, answer the following question: {query}.  3) Give quotes that validate your answer in <quotes> </quotes> xml tags.  4. Give your final answer in <final_answer> </final_answer> xml tags.\"\n",
        "    response =get_completion(prompt)\n",
        "    pattern = r\"<final_answer>(.*?)</final_answer>\"\n",
        "    answer = next(iter(re.findall(pattern, response, re.DOTALL)))\n",
        "    return answer"
      ],
      "metadata": {
        "id": "736TYdJBMxFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some Sample Uses"
      ],
      "metadata": {
        "id": "t673C0GcM5nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"What's the name of the latest material that was claimed to be a room temperature superconductor?\",\n",
        "    \"Which team did the Denver Nuggets beat in the 2023 NBA finals?\",\n",
        "    \"Where are the two biggest particle accelerators in the continental United States?\"\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "  print(f\"-------------{question}-------------\")\n",
        "  print(ask_clawd(question))"
      ],
      "metadata": {
        "id": "97wCv17hNBX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e627922-482a-477c-e587-115ea3411f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------What's the name of the latest material that was claimed to be a room temperature superconductor?-------------\n",
            "%s -> %s (\"What's the name of the latest material that was claimed to be a room temperature superconductor?\", '\"room temperature superconductor\"')\n",
            "\n",
            "The latest material claimed to be a room temperature superconductor is called LK-99 or copper-doped lead apatite.\n",
            "\n",
            "-------------Which team did the Denver Nuggets beat in the 2023 NBA finals?-------------\n",
            "%s -> %s ('Which team did the Denver Nuggets beat in the 2023 NBA finals?', '\"2023 NBA finals Denver Nuggets opponent\"')\n",
            "\n",
            "Fictional 2023 NBA Finals opponent for the Denver Nuggets\n",
            "\n",
            "-------------Where are the two biggest particle accelerators in the continental United States?-------------\n",
            "%s -> %s ('Where are the two biggest particle accelerators in the continental United States?', 'The rephrased prompt for lookup in Wikipedia would be: two biggest particle accelerators in continental United States')\n",
            "\n",
            "The two biggest particle accelerators in the continental United States are the Relativistic Heavy Ion Collider (RHIC) at Brookhaven National Laboratory in New York and the Tevatron at Fermilab in Illinois.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a multiple choice test\n",
        "\n",
        "Generate 3 question multiple choice test about a given subject, where each question has four options, only one of which is true."
      ],
      "metadata": {
        "id": "a9SFTLddO2ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import random\n",
        "def generate_test_with_clawd(subject: str):\n",
        "  subjects = []\n",
        "\n",
        "  subjects = [subject] * 4\n",
        "  questions = []\n",
        "  for subject_alt in subjects:\n",
        "\n",
        "    search_results = get_wikipedia_search_results(subject_alt, n_search_results_to_use=3)\n",
        "    search_results_list = ['<title>\\n%s\\n</title>\\n<source>\\n%s</source>\\n<content>%s</content>' % (d['title'], d['source'], d['content']) for d in search_results]\n",
        "    template = f'<question>Example Question\\n<answers>\\n(A) Example Answer 1\\n(B) Example Answer 2\\n(C) Example Answer 3\\n(D) Example Answer 4\\n</answers>\\n</question>'\n",
        "\n",
        "    search_results_concat = '\\n'.join(search_results_list)\n",
        "    random.shuffle(search_results_list)\n",
        "    prompt = f\"{search_results_concat}\\n\\nQuestions so far (used before):\\n {questions}.\\n End of questions so far.\\n\\n\\n  \\nGive a totally new question on the subject {subject_alt}.  Be absolutely sure that the new question is not the same as any of the original questions so far.  Only one answer, choose A, B, C, or D randomly, is the correct answer.  The answers should be brief 1-2 words at most.  Follow this template:\\n{template}.  Remember, ensure you make totally new questions compared to those already used before.\"\n",
        "    #print(prompt)\n",
        "    response = get_completion(prompt, temperature=0)\n",
        "    #print(response)\n",
        "    pattern = r\"<question>(.*?)</question>\"\n",
        "    question1 = next(iter(re.findall(pattern, response, re.DOTALL)))\n",
        "    questions.append(question1)\n",
        "\n",
        "  return '\\n'.join(questions)"
      ],
      "metadata": {
        "id": "oU8-IXkWRvMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some Sample Uses (feel free to add more)"
      ],
      "metadata": {
        "id": "CD4Q2CrDR5mZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subjects = [\n",
        "    \"The French Revolution\",\n",
        "    \"Covid-19 in 2023\"\n",
        "]\n",
        "\n",
        "for subject in subjects:\n",
        "  print(f\"-------------{subject}-------------\")\n",
        "  print(generate_test_with_clawd(subject))"
      ],
      "metadata": {
        "id": "jucSz05-R6jL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06c0f222-79b5-42c7-eb03-5a5076bb50f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------The French Revolution-------------\n",
            "What event in July 1830 led to the overthrow of King Charles X?\n",
            "<answers>  \n",
            "(A) The July Revolution\n",
            "(B) The June Rebellion\n",
            "(C) The Reign of Terror\n",
            "(D) The Storming of the Bastille\n",
            "</answers>\n",
            "\n",
            "What event in July 1830 led King Charles X to abdicate the throne? \n",
            "<answers>\n",
            "(A) The June Rebellion\n",
            "(B) The July Ordinances\n",
            "(C) The Reign of Terror\n",
            "(D) The Storming of the Bastille\n",
            "</answers>\n",
            "\n",
            "What event in 1789 led to the formation of the National Assembly in France?\n",
            "<answers>  \n",
            "(A) Storming of the Bastille\n",
            "(B) Reign of Terror\n",
            "(C) Fête de la Fédération \n",
            "(D) July Revolution\n",
            "</answers>\n",
            "\n",
            "\n",
            "What event in 1791 caused the royal family to flee Paris?\n",
            "<answers>  \n",
            "(A) The Flight to Varennes\n",
            "(B) The Reign of Terror\n",
            "(C) The Storming of the Bastille\n",
            "(D) The July Revolution\n",
            "</answers>\n",
            "\n",
            "-------------Covid-19 in 2023-------------\n",
            "\n",
            "What percent of the US population is estimated to have had COVID-19 by the end of 2022?\n",
            "<answers>  \n",
            "(A) 50% \n",
            "(B) 60%\n",
            "(C) 70%  \n",
            "(D) 80%\n",
            "</answers>\n",
            "\n",
            "\n",
            "What percent of the US population is estimated to have had COVID-19 by the end of 2023?\n",
            "<answers>  \n",
            "(A) 80%\n",
            "(B) 85% \n",
            "(C) 90%\n",
            "(D) 95%\n",
            "</answers>\n",
            "\n",
            "\n",
            "What percent of Americans are estimated to get a bivalent booster by the end of 2023?  \n",
            "<answers>\n",
            "(A) 40%  \n",
            "(B) 50%\n",
            "(C) 60%\n",
            "(D) 70%\n",
            "</answers>\n",
            "\n",
            "What percent of Americans are estimated to get the bivalent booster by July 2023?\n",
            "<answers>  \n",
            "(A) 60%\n",
            "(B) 70% \n",
            "(C) 80%\n",
            "(D) 90%\n",
            "</answers>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can easily extract the answers etc.\n",
        "# we can also rephrase the target subject for wikipedia if required"
      ],
      "metadata": {
        "id": "3w-E6O-tbVEW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}